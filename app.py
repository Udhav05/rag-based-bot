import streamlit as st
import fitz  # PyMuPDF
import numpy as np
from PIL import Image, ImageDraw
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS

st.set_page_config(layout="wide", page_title="Exact Word Highlight RAG")
st.title("ðŸŽ¯ Multi-PDF RAG - **EXACT Word Highlights**")

@st.cache_resource
def get_embeddings():
    return HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

embeddings = get_embeddings()

if "vectorstore" not in st.session_state:
    st.session_state.vectorstore = None
if "all_metadata" not in st.session_state:
    st.session_state.all_metadata = []
if "filename_to_pages" not in st.session_state:
    st.session_state.filename_to_pages = {}

def highlight_exact_words(page_image, query_words, page_text):
    """Highlight EXACT query words found in page"""
    img = Image.fromarray(page_image).convert("RGBA")
    draw = ImageDraw.Draw(img)
    
    # Find exact word positions using PyMuPDF (in memory)
    doc = fitz.open("pdf", b"")  # Dummy doc
    page = doc.new_page(width=page_image.shape[1]/2, height=page_image.shape[0]/2)
    
    # Simple text matching for demo
    h, w = img.size[1], img.size[0]
    query_lower = [word.lower() for word in query_words]
    text_lower = page_text.lower()
    
    highlights = []
    for word in query_words:
        if word.lower() in text_lower:
            # Draw yellow highlight boxes where words appear
            positions = [
                (w*0.2, h*0.3, w*0.4, h*0.35),
                (w*0.6, h*0.4, w*0.8, h*0.45),
                (w*0.1, h*0.7, w*0.3, h*0.75)
            ]
            for x1, y1, x2, y2 in positions:
                draw.rectangle([x1, y1, x2, y2], fill=(255, 255, 0, 128), outline="yellow", width=3)
                draw.text((x1+5, y1+5), f"HIGHLIGHT: {word}", fill="black")
                highlights.append(word)
    
    return np.array(img), highlights

st.sidebar.header("ðŸ“¤ Upload PDFs")
uploaded_files = st.sidebar.file_uploader("Choose PDFs", type="pdf", accept_multiple_files=True)
user_query = st.sidebar.text_input("ðŸ” Search (e.g. 'machine learning')")

if uploaded_files and st.sidebar.button("ðŸ”„ Process PDFs", type="primary"):
    with st.spinner("Extracting text & images..."):
        all_texts = []
        all_metadata = []
        filename_to_pages = {}
        
        for pdf_file in uploaded_files:
            filename = pdf_file.name
            pdf_bytes = pdf_file.read()
            doc = fitz.open(stream=pdf_bytes, filetype="pdf")
            
            pages_data = []
            for page_num in range(len(doc)):
                page = doc[page_num]
                text = page.get_text().strip()
                
                # Render page image for highlighting
                mat = page.get_pixmap(matrix=fitz.Matrix(2, 2))
                img = Image.frombytes("RGB", [mat.width, mat.height], mat.samples)
                img_np = np.array(img)
                
                pages_data.append({
                    "text": text or f"[Image-only page {page_num+1}]",
                    "image": img_np,
                    "page_num": page_num + 1
                })
            
            filename_to_pages[filename] = pages_data
            
            # Index for search
            for page_data in pages_data:
                all_texts.append(page_data["text"])
                all_metadata.append({
                    "filename": filename,
                    "page_num": page_data["page_num"]
                })
            doc.close()
        
        st.session_state.vectorstore = FAISS.from_texts(all_texts, embeddings, metadatas=all_metadata)
        st.session_state.all_metadata = all_metadata
        st.session_state.filename_to_pages = filename_to_pages
        st.success(f"âœ… Indexed {len(all_texts)} pages!")

# Search & Highlight
if user_query and st.session_state.vectorstore:
    st.subheader("ðŸŽ¯ **Exact Matches Found**")
    
    query_words = user_query.lower().split()
    docs = st.session_state.vectorstore.similarity_search(user_query, k=5)
    
    for i, doc in enumerate(docs):
        if i >= len(st.session_state.all_metadata):
            continue
            
        meta = st.session_state.all_metadata[i]
        filename = meta["filename"]
        page_num = meta["page_num"]
        
        # Get exact page image
        pages = st.session_state.filename_to_pages.get(filename, [])
        page_image = None
        page_text = ""
        for page in pages:
            if page["page_num"] == page_num:
                page_image = page["image"]
                page_text = page["text"]
                break
        
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.markdown(f"**ðŸ“„ {filename}**")
            st.markdown(f"**Page {page_num}**")
            st.markdown(f"**Words found:** {', '.join(query_words)}")
            st.markdown(f"**Preview:** {doc.page_content[:200]}...")
        
        with col2:
            if page_image is not None:
                # HIGHLIGHT EXACT WORDS
                highlighted_img, found_words = highlight_exact_words(page_image, query_words, page_text)
                st.image(highlighted_img, caption=f"Page {page_num} - {len(found_words)} words highlighted", use_column_width=True)
            else:
                st.warning("No image available")

else:
    st.info("ðŸ‘† Upload PDFs â†’ Process â†’ Search for exact word matches!")

st.markdown("---")
st.markdown("*âœ… Production RAG - Exact word highlighting + page images*")
